{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Averaged Density-Speed Analysis Across Simulations\n",
        "\n",
        "This notebook aggregates `output_1` ... `output_10` (or any `output_<int>` folders),\n",
        "aligns them to a common time horizon, bins by mean density, averages normalized street\n",
        "speeds across all compatible realizations, saves mean/error matrices, and reruns the same\n",
        "class analysis and plots from `minimal_density_speed.ipynb` on averaged data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"..\")\n",
        "OUTPUT_DIR = ROOT / \"output_avg\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TIME_COL = \"time_step\"\n",
        "DENSITY_COL = \"mean_density_vpk\"\n",
        "\n",
        "\n",
        "def discover_simulation_dirs(root: Path):\n",
        "    dirs = []\n",
        "    for p in root.iterdir():\n",
        "        if not p.is_dir() or not p.name.startswith(\"output_\"):\n",
        "            continue\n",
        "        suffix = p.name.split(\"_\", 1)[1]\n",
        "        if suffix.isdigit():\n",
        "            dirs.append(p)\n",
        "    return sorted(dirs, key=lambda x: int(x.name.split(\"_\")[1]))\n",
        "\n",
        "\n",
        "sim_dirs = discover_simulation_dirs(ROOT)\n",
        "if not sim_dirs:\n",
        "    raise RuntimeError(\"No output_<int> simulation folders found.\")\n",
        "\n",
        "print(f\"Discovered simulations: {[p.name for p in sim_dirs]}\")\n",
        "print(f\"Aggregation output folder: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate required inputs\n",
        "required_files = [\"data.csv\", \"stability_timestep.csv\", \"normalized_street_speeds.csv\"]\n",
        "missing = []\n",
        "\n",
        "for d in sim_dirs:\n",
        "    for fn in required_files:\n",
        "        if not (d / fn).exists():\n",
        "            missing.append(str(d / fn))\n",
        "\n",
        "if missing:\n",
        "    raise FileNotFoundError(\n",
        "        \"Missing required files:\\n\" + \"\\n\".join(missing)\n",
        "    )\n",
        "\n",
        "print(\"All required input files are present.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute per-simulation last timestep from data.csv and common truncation limit\n",
        "last_rows = []\n",
        "\n",
        "for d in sim_dirs:\n",
        "    data = pd.read_csv(d / \"data.csv\", sep=\";\").sort_values(TIME_COL)\n",
        "    if data.empty:\n",
        "        continue\n",
        "    last_rows.append(\n",
        "        {\n",
        "            \"simulation\": d.name,\n",
        "            \"last_time_step\": float(data[TIME_COL].iloc[-1]),\n",
        "            \"samples\": int(len(data)),\n",
        "        }\n",
        "    )\n",
        "\n",
        "if not last_rows:\n",
        "    raise RuntimeError(\"No data rows found in simulation folders.\")\n",
        "\n",
        "last_timestep_df = pd.DataFrame(last_rows).sort_values(\"simulation\")\n",
        "common_time_limit = int(last_timestep_df[\"last_time_step\"].min())\n",
        "\n",
        "limit_path = OUTPUT_DIR / \"simulation_last_timesteps.csv\"\n",
        "last_timestep_df.to_csv(limit_path, index=False, sep=\";\")\n",
        "\n",
        "print(last_timestep_df)\n",
        "print(f\"Common truncation limit (min last timestep): {common_time_limit}\")\n",
        "print(f\"Saved per-run timestep summary: {limit_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick one random stability_timestep.csv and use its step count (<= common limit) as number of bins\n",
        "rng = np.random.default_rng(RANDOM_SEED)\n",
        "reference_dir = sim_dirs[int(rng.integers(0, len(sim_dirs)))]\n",
        "\n",
        "reference_stability = (\n",
        "    pd.read_csv(reference_dir / \"stability_timestep.csv\", sep=\";\")\n",
        "    .sort_values(TIME_COL)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "reference_truncated = reference_stability[reference_stability[TIME_COL] <= common_time_limit]\n",
        "n_bins = int(len(reference_truncated))\n",
        "\n",
        "if n_bins <= 0:\n",
        "    raise RuntimeError(\n",
        "        f\"Reference stability file {reference_dir/'stability_timestep.csv'} has no rows at or before time limit {common_time_limit}.\"\n",
        "    )\n",
        "\n",
        "print(f\"Random reference simulation: {reference_dir.name}\")\n",
        "print(f\"Reference stability rows up to limit: {n_bins}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and truncate normalized speed matrices, then define constant-width mean-density bins\n",
        "normalized_runs = []\n",
        "pooled_density = []\n",
        "\n",
        "for d in sim_dirs:\n",
        "    df = (\n",
        "        pd.read_csv(d / \"normalized_street_speeds.csv\", sep=\";\")\n",
        "        .sort_values(TIME_COL)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    df = df[df[TIME_COL] <= common_time_limit].copy()\n",
        "    df[\"simulation\"] = d.name\n",
        "\n",
        "    normalized_runs.append(df)\n",
        "    pooled_density.append(df[DENSITY_COL].dropna())\n",
        "\n",
        "if not pooled_density:\n",
        "    raise RuntimeError(\"No density data available after truncation.\")\n",
        "\n",
        "all_density = pd.concat(pooled_density, ignore_index=True)\n",
        "density_min = float(all_density.min())\n",
        "density_max = float(all_density.max())\n",
        "\n",
        "if density_min == density_max:\n",
        "    bin_edges = np.array([density_min, density_max + 1e-9])\n",
        "    n_bins = 1\n",
        "else:\n",
        "    bin_edges = np.linspace(density_min, density_max, n_bins + 1)\n",
        "\n",
        "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
        "\n",
        "bins_df = pd.DataFrame(\n",
        "    {\n",
        "        \"bin_id\": np.arange(1, len(bin_centers) + 1),\n",
        "        \"density_low\": bin_edges[:-1],\n",
        "        \"density_high\": bin_edges[1:],\n",
        "        \"density_midpoint\": bin_centers,\n",
        "    }\n",
        ")\n",
        "bins_path = OUTPUT_DIR / \"density_bins.csv\"\n",
        "bins_df.to_csv(bins_path, index=False, sep=\";\")\n",
        "\n",
        "print(f\"Density range: [{density_min:.4f}, {density_max:.4f}]\")\n",
        "print(f\"Number of bins: {len(bin_centers)}\")\n",
        "print(f\"Saved bins: {bins_path}\")\n",
        "bins_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate means/stds of normalized street speeds for each density bin\n",
        "ignore_cols = {\"datetime\", TIME_COL, DENSITY_COL, \"simulation\"}\n",
        "street_cols = sorted(\n",
        "    set().union(*[{c for c in df.columns if c not in ignore_cols} for df in normalized_runs])\n",
        ")\n",
        "\n",
        "mean_rows = []\n",
        "err_rows = []\n",
        "bin_meta_rows = []\n",
        "\n",
        "for i, (lo, hi, mid) in enumerate(zip(bin_edges[:-1], bin_edges[1:], bin_centers), start=1):\n",
        "    per_run_matches = []\n",
        "    for df in normalized_runs:\n",
        "        if i < len(bin_centers):\n",
        "            mask = (df[DENSITY_COL] >= lo) & (df[DENSITY_COL] < hi)\n",
        "        else:\n",
        "            mask = (df[DENSITY_COL] >= lo) & (df[DENSITY_COL] <= hi)\n",
        "        matched = df.loc[mask]\n",
        "        if not matched.empty:\n",
        "            per_run_matches.append(matched)\n",
        "\n",
        "    if per_run_matches:\n",
        "        matched_rows = pd.concat(per_run_matches, ignore_index=True, sort=False)\n",
        "    else:\n",
        "        matched_rows = pd.DataFrame(columns=[DENSITY_COL, *street_cols])\n",
        "\n",
        "    mean_row = {TIME_COL: i, DENSITY_COL: mid}\n",
        "    err_row = {TIME_COL: i, DENSITY_COL: mid}\n",
        "\n",
        "    density_vals = pd.to_numeric(matched_rows.get(DENSITY_COL), errors=\"coerce\").dropna()\n",
        "    if len(density_vals) > 0:\n",
        "        # RMS spread around the bin midpoint (requested density error wrt midpoint)\n",
        "        density_std_midpoint = float(np.sqrt(np.mean((density_vals - mid) ** 2)))\n",
        "        density_std_sample = float(density_vals.std(ddof=1)) if len(density_vals) > 1 else np.nan\n",
        "    else:\n",
        "        density_std_midpoint = np.nan\n",
        "        density_std_sample = np.nan\n",
        "\n",
        "    err_row[\"density_std_midpoint\"] = density_std_midpoint\n",
        "    err_row[\"density_std_sample\"] = density_std_sample\n",
        "\n",
        "    for col in street_cols:\n",
        "        if col in matched_rows.columns:\n",
        "            vals = pd.to_numeric(matched_rows[col], errors=\"coerce\").dropna()\n",
        "        else:\n",
        "            vals = pd.Series(dtype=float)\n",
        "\n",
        "        mean_row[col] = float(vals.mean()) if len(vals) > 0 else np.nan\n",
        "        err_row[col] = float(vals.std(ddof=1)) if len(vals) > 1 else np.nan\n",
        "\n",
        "    mean_rows.append(mean_row)\n",
        "    err_rows.append(err_row)\n",
        "    bin_meta_rows.append(\n",
        "        {\n",
        "            \"bin_id\": i,\n",
        "            \"density_low\": lo,\n",
        "            \"density_high\": hi,\n",
        "            \"density_midpoint\": mid,\n",
        "            \"matched_rows\": int(len(matched_rows)),\n",
        "            \"matched_simulations\": int(matched_rows[\"simulation\"].nunique()) if \"simulation\" in matched_rows.columns and not matched_rows.empty else 0,\n",
        "        }\n",
        "    )\n",
        "\n",
        "avg_normalized_df = pd.DataFrame(mean_rows)\n",
        "avg_errors_df = pd.DataFrame(err_rows)\n",
        "bin_meta_df = pd.DataFrame(bin_meta_rows)\n",
        "\n",
        "avg_path = OUTPUT_DIR / \"normalized_street_speeds.csv\"\n",
        "err_path = OUTPUT_DIR / \"normalized_street_speeds_errors.csv\"\n",
        "meta_path = OUTPUT_DIR / \"aggregation_bin_summary.csv\"\n",
        "\n",
        "avg_normalized_df.to_csv(avg_path, index=False, sep=\";\")\n",
        "avg_errors_df.to_csv(err_path, index=False, sep=\";\")\n",
        "bin_meta_df.to_csv(meta_path, index=False, sep=\";\")\n",
        "\n",
        "print(f\"Street columns aggregated: {len(street_cols)}\")\n",
        "print(f\"Saved averaged matrix: {avg_path}\")\n",
        "print(f\"Saved error matrix: {err_path}\")\n",
        "print(f\"Saved bin aggregation summary: {meta_path}\")\n",
        "avg_normalized_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot averaged normalized speed curves vs binned mean density\n",
        "keep_streets = [c for c in street_cols if c in avg_normalized_df.columns and avg_normalized_df[c].notna().any()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 12))\n",
        "for col in keep_streets:\n",
        "    series = avg_normalized_df[col]\n",
        "    mask = series.notna() & avg_normalized_df[DENSITY_COL].notna()\n",
        "    if mask.sum() < 2:\n",
        "        continue\n",
        "    ax.plot(\n",
        "        avg_normalized_df[DENSITY_COL][mask],\n",
        "        series[mask],\n",
        "        marker=\"o\",\n",
        "        markersize=2,\n",
        "        linewidth=0.8,\n",
        "        alpha=0.35,\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(\"Mean density (veh/km)\")\n",
        "ax.set_ylabel(\"Speed / maxspeed (ratio)\")\n",
        "ax.set_xlim(0, 20)\n",
        "ax.set_title(\"Averaged normalized street speeds vs mean density\")\n",
        "ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "\n",
        "plot_path = OUTPUT_DIR / \"norm_speeds_vs_density.png\"\n",
        "plt.savefig(plot_path, dpi=500)\n",
        "print(f\"Saved plot: {plot_path}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Same class analysis as minimal_density_speed, now on averaged data\n",
        "WINDOW_BAND = 2.5\n",
        "DENSITY_START = 2\n",
        "DENSITY_END = 20\n",
        "\n",
        "windows = []\n",
        "low = DENSITY_START\n",
        "high = low + WINDOW_BAND\n",
        "while high <= DENSITY_END + 1e-9:\n",
        "    windows.append((low, min(high, DENSITY_END + 1e-9)))\n",
        "    high += WINDOW_BAND\n",
        "\n",
        "classes = {f\"{lo:.2f}-{hi:.2f}\": [] for lo, hi in windows}\n",
        "\n",
        "for col in keep_streets:\n",
        "    ratio = avg_normalized_df[col]\n",
        "    for lo, hi in windows:\n",
        "        label = f\"{lo:.2f}-{hi:.2f}\"\n",
        "        mask = (avg_normalized_df[DENSITY_COL] >= lo) & (avg_normalized_df[DENSITY_COL] < hi)\n",
        "        vals = ratio[mask].dropna()\n",
        "        if vals.empty:\n",
        "            continue\n",
        "        hi_idx = vals[vals > 0.55].index.min()\n",
        "        if pd.isna(hi_idx):\n",
        "            continue\n",
        "        later = vals.loc[vals.index > hi_idx]\n",
        "        if (later < 0.35).any():\n",
        "            classes[label].append(col)\n",
        "            break\n",
        "\n",
        "classes = {k: v for k, v in classes.items() if v}\n",
        "print(f\"Classes found: {len(classes)}\")\n",
        "for lbl, streets in classes.items():\n",
        "    print(f\"  {lbl}: {len(streets)} streets\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot classes on the map with different colors\n",
        "edges = pd.read_csv(ROOT / \"input\" / \"edges_tl.csv\", sep=\";\")\n",
        "\n",
        "if not classes:\n",
        "    print(\"No classes found; adjust WINDOW_BAND / thresholds.\")\n",
        "else:\n",
        "    geom_map = edges.set_index(edges[\"id\"].astype(str))[\"geometry\"].to_dict()\n",
        "\n",
        "    def parse_linestring(wkt):\n",
        "        if not isinstance(wkt, str) or \"LINESTRING\" not in wkt:\n",
        "            return None\n",
        "        inner = wkt.split(\"(\", 1)[1].rsplit(\")\", 1)[0]\n",
        "        coords = []\n",
        "        for pair in inner.split(','):\n",
        "            parts = pair.strip().split()\n",
        "            if len(parts) != 2:\n",
        "                continue\n",
        "            x, y = map(float, parts)\n",
        "            coords.append((x, y))\n",
        "        return coords if coords else None\n",
        "\n",
        "    colors = plt.cm.tab20.colors\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    for sid, geom in geom_map.items():\n",
        "        coords = parse_linestring(geom)\n",
        "        if not coords:\n",
        "            continue\n",
        "        xs, ys = zip(*coords)\n",
        "        ax.plot(xs, ys, color=\"lightgray\", linewidth=0.6, alpha=0.3)\n",
        "\n",
        "    for idx, (label, streets) in enumerate(classes.items()):\n",
        "        color = colors[idx % len(colors)]\n",
        "        for sid in streets:\n",
        "            geom = geom_map.get(str(sid))\n",
        "            coords = parse_linestring(geom)\n",
        "            if not coords:\n",
        "                continue\n",
        "            xs, ys = zip(*coords)\n",
        "            ax.plot(\n",
        "                xs,\n",
        "                ys,\n",
        "                color=color,\n",
        "                linewidth=2.0,\n",
        "                alpha=0.9,\n",
        "                label=label if idx == list(classes.keys()).index(label) else None,\n",
        "            )\n",
        "\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    unique = dict(zip(labels, handles))\n",
        "    if unique:\n",
        "        ax.legend(unique.values(), unique.keys(), title=\"Density window\")\n",
        "    ax.set_title(\"Streets with ratio drop (>0.55 then <0.35) within density windows\")\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "    map_path = OUTPUT_DIR / \"drop_speeds_map.png\"\n",
        "    plt.savefig(map_path, dpi=500)\n",
        "    plt.tight_layout()\n",
        "    print(f\"Saved plot: {map_path}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot averaged normalized speed ratios with class highlights\n",
        "if not classes:\n",
        "    print(\"No classes available; run the classification cell or adjust thresholds.\")\n",
        "else:\n",
        "    class_streets = {s for streets in classes.values() for s in streets}\n",
        "    colors = plt.cm.tab20.colors\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    for col in keep_streets:\n",
        "        if col in class_streets:\n",
        "            continue\n",
        "        series = avg_normalized_df[col]\n",
        "        mask = series.notna() & avg_normalized_df[DENSITY_COL].notna()\n",
        "        if mask.sum() < 2:\n",
        "            continue\n",
        "        ax.plot(\n",
        "            avg_normalized_df[DENSITY_COL][mask],\n",
        "            series[mask],\n",
        "            color=\"lightgray\",\n",
        "            marker=\"o\",\n",
        "            markersize=2,\n",
        "            linewidth=0.8,\n",
        "            alpha=0.4,\n",
        "        )\n",
        "\n",
        "    for idx, (label, streets) in enumerate(classes.items()):\n",
        "        color = colors[idx % len(colors)]\n",
        "        for col in streets:\n",
        "            if col not in avg_normalized_df.columns:\n",
        "                continue\n",
        "            series = avg_normalized_df[col]\n",
        "            mask = series.notna() & avg_normalized_df[DENSITY_COL].notna()\n",
        "            if mask.sum() < 2:\n",
        "                continue\n",
        "            ax.plot(\n",
        "                avg_normalized_df[DENSITY_COL][mask],\n",
        "                series[mask],\n",
        "                color=color,\n",
        "                marker=\"o\",\n",
        "                markersize=2.5,\n",
        "                linewidth=1.0,\n",
        "                alpha=0.9,\n",
        "                label=label,\n",
        "            )\n",
        "\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    unique = dict(zip(labels, handles))\n",
        "    if unique:\n",
        "        ax.legend(unique.values(), unique.keys(), title=\"Density window classes\")\n",
        "\n",
        "    ax.set_xlabel(\"Mean density (veh/km)\")\n",
        "    ax.set_ylabel(\"Speed / maxspeed (ratio)\")\n",
        "    ax.set_xlim(0, 20)\n",
        "    ax.set_title(\"Averaged normalized street speeds vs mean density with class highlights\")\n",
        "    ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "    class_plot_path = OUTPUT_DIR / \"drop_speeds_classes.png\"\n",
        "    plt.savefig(class_plot_path, dpi=500)\n",
        "    plt.tight_layout()\n",
        "    print(f\"Saved plot: {class_plot_path}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save selected streets with class assignment\n",
        "if not classes:\n",
        "    print(\"No classes to save; run classification or adjust thresholds.\")\n",
        "else:\n",
        "    class_rows = []\n",
        "    for idx, (label, streets) in enumerate(classes.items(), start=1):\n",
        "        for sid in streets:\n",
        "            class_rows.append((sid, idx))\n",
        "    class_map = dict(class_rows)\n",
        "\n",
        "    edges_copy = edges.copy()\n",
        "    edges_copy[\"id_str\"] = edges_copy[\"id\"].astype(str)\n",
        "    edges_copy[\"class\"] = edges_copy[\"id_str\"].map(class_map)\n",
        "    selected = edges_copy[edges_copy[\"class\"].notna()].copy()\n",
        "\n",
        "    selected_path = OUTPUT_DIR / \"selected_streets.csv\"\n",
        "    selected.to_csv(selected_path, index=False, sep=\";\")\n",
        "    print(f\"Saved {len(selected)} selected streets to {selected_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}